<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><meta name="exporter-version" content="Evernote Mac 9.5.12 (464966)"/><meta name="author" content="Ἅιδης"/><meta name="created" content="2021-03-04 14:58:51 +0000"/><meta name="source" content="desktop.mac"/><meta name="updated" content="2021-03-06 13:16:10 +0000"/><title>6.2 决策树实战练习</title></head><body><div>DictVectorizer()  onehotEncode() get_dummies三种</div><div><a href="https://blog.csdn.net/qq_40913605/article/details/86688227">https://blog.csdn.net/qq_40913605/article/details/86688227</a></div><div><br/></div><div>DictVectorizer() 是对字符串变量进行热码</div><div>onehotEncode() 是对数字分类的变量做热码，如果非要对字符型变量进行编码，可以先用自然编码labelEncoder,效果等同于DictVectorizer</div><div><br/></div><div>在数据预处理中，对离散无序数据的编码通常的做法是：在训练集上生成编码规则，测试集的数据编码直接调用已生成的规则，以确保模型可以处理所有数据。</div><div>当测试集出现基于训练集的编码规则没见过的数据时，DictVectorizer、OneHotEncoder将未见过数据编码全为0来处理；但是但get_dummies没有这样的用法，它只能在新数据上新建一套编码规则，当训练集上的编码规则与测试集上的不完全一致时，get_dummies也没有相应的应对措施，这时模型就不知道该如何处理未见过的数据了。</div><div>————————————————</div><div><br/></div><div>画决策树重点就在于两个部分</div><div><br/></div><div>feature_names = vec.get_feature_names(),</div><div>class_names = lb.classes_,</div><div><br/></div><div><img src="6.2%20%E5%86%B3%E7%AD%96%E6%A0%91%E5%AE%9E%E6%88%98%E7%BB%83%E4%B9%A0.resources/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202021-03-05%2019.38.04.png" height="844" width="1666"/><br/></div><div><br/></div><div><br/></div><div>#cart算法剪枝可以参考<a href="https://blog.csdn.net/zhengzhenxian/article/details/79083643">https://blog.csdn.net/zhengzhenxian/article/details/79083643</a></div><div><br/></div><div>剪枝算法实际参考案例<a href="https://blog.csdn.net/weixin_39997400/article/details/111293447?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.control&amp;dist_request_id=&amp;depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.control">https://blog.csdn.net/weixin_39997400/article/details/111293447?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.control&amp;dist_request_id=&amp;depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.control</a></div><div><br/></div><div><span style="font-size: 24px;">画等高线的这种方法很重要，就是在一个区域上meshgrid</span></div><div><img src="6.2%20%E5%86%B3%E7%AD%96%E6%A0%91%E5%AE%9E%E6%88%98%E7%BB%83%E4%B9%A0.resources/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202021-03-06%2001.28.09.png" height="566" width="1188"/><br/></div><div><span style="font-size: 24px;"><br/></span></div><div><span style="font-size: 24px;">关于决策树的参数可以参考</span></div><div><span style="font-size: 24px;"><a href="https://blog.csdn.net/qq_41577045/article/details/79844709">https://blog.csdn.net/qq_41577045/article/details/79844709</a></span></div></body></html>