<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html><head><title>已导出笔记的索引</title></head><body>
<a href="%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%BB%A5%E5%8F%8A%E9%9D%9E%E7%BA%BF%E5%BD%A2%E5%9B%9E%E5%BD%92.html">线性回归以及非线形回归</a><br/>
<a href="7.3%20Stacking%20%E7%AE%97%E6%B3%95.html">7.3 Stacking 算法</a><br/>
<a href="2.7%20%E8%BF%87%E6%8B%9F%E5%90%88%20%E6%AD%A3%E5%88%99%E5%8C%96.html">2.7 过拟合 正则化</a><br/>
<a href="5.1%20%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95.html">5.1 贝叶斯算法</a><br/>
<a href="10.1%20Arima%E6%A8%A1%E5%9E%8B.html">10.1 Arima模型</a><br/>
<a href="2.12%20%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%9B%9E%E5%BD%92.html">2.12 多项式回归</a><br/>
<a href="7.1%20bagging%20%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BD%BF%E7%94%A8.html">7.1 bagging 介绍与使用</a><br/>
<a href="%E6%97%A0%E6%A0%87%E9%A2%98.html">无标题</a><br/>
<a href="8.1%20pca%E9%99%8D%E7%BB%B4.html">8.1 pca降维</a><br/>
<a href="2.8.1%20%20longley%E6%95%B0%E6%8D%AE%E9%9B%86(%E5%B2%AD%E5%9B%9E%E5%BD%92%EF%BC%89.html">2.8.1  longley数据集(岭回归）</a><br/>
<a href="9.1%20SVM.html">9.1 SVM</a><br/>
<a href="2.3.1%20%20%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%BA%93.html">2.3.1  一元线性回归库</a><br/>
<a href="3.2%20%E6%AD%A3%E7%A1%AE%E7%8E%87%20%E5%8F%AC%E5%9B%9E%E7%8E%87%20F1%20%E6%8C%87%E6%A0%87.html">3.2 正确率 召回率 F1 指标</a><br/>
<a href="7.2%20%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E7%9A%84%E4%BD%BF%E7%94%A8.html">7.2 随机森林的使用</a><br/>
<a href="2.1%20%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92.html">2.1 一元线性回归</a><br/>
<a href="2.3%20%E6%A2%AF%E9%98%9F%E4%B8%8B%E9%99%8D%E6%B3%95%20%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92.html">2.3 梯队下降法 一元线性回归</a><br/>
<a href="2.8%20%E5%B2%AD%E5%9B%9E%E5%BD%92%EF%BC%88L2%E6%AD%A3%E5%88%99%E5%8C%96%EF%BC%89.html">2.8 岭回归（L2正则化）</a><br/>
<a href="%E5%BD%92%E4%B8%80%E5%8C%96%E6%80%BB%E7%BB%93.html">归一化总结</a><br/>
<a href="4.29%20%20%E5%85%AC%E5%8F%B8%E7%AC%94%E8%AE%B0.html">4.29  公司笔记</a><br/>
<a href="1%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.html">1 机器学习基本概念</a><br/>
<a href="2.4%20%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92.html">2.4 多元线性回归</a><br/>
<a href="3.3%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E8%AF%AD%E6%B3%95%E6%80%BB%E7%BB%93.html">3.3 逻辑回归语法总结</a><br/>
<a href="6.3%20cart%E5%88%86%E7%B1%BB%E6%A0%91%E5%92%8Ccart%E5%9B%9E%E5%BD%92%E6%A0%91.html">6.3 cart分类树和cart回归树</a><br/>
<a href="%E6%97%A0%E6%A0%87%E9%A2%98_1.html">无标题</a><br/>
<a href="2.10%20%E5%BC%B9%E6%80%A7%E7%BD%91.html">2.10 弹性网</a><br/>
<a href="%E6%97%A0%E6%A0%87%E9%A2%98_2.html">无标题</a><br/>
<a href="2.4.1%20%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%BA%93.html">2.4.1 多元线性回归库</a><br/>
<a href="4.1%20%E6%9C%80%E8%BF%91%E9%82%BB%E8%A7%84%E5%88%99%E5%88%86%E7%B1%BB%20KNN.html">4.1 最近邻规则分类 KNN</a><br/>
<a href="6.4%20GBDT%E7%AE%97%E6%B3%95.html">6.4 GBDT算法</a><br/>
<a href="2.2%20%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0.html">2.2 代价函数</a><br/>
<a href="2.9%20%20LASSO%E7%AE%97%E6%B3%95%20%EF%BC%88L1%E6%AD%A3%E5%88%99%E5%8C%96%EF%BC%89.html">2.9  LASSO算法 （L1正则化）</a><br/>
<a href="6.1%20%E5%86%B3%E7%AD%96%E6%A0%91%EF%BC%8C%E4%BF%A1%E6%81%AF%E7%86%B5%EF%BC%8Cid3,%20c4.5%E7%AE%97%E6%B3%95%E4%BB%8B%E7%BB%8D.html">6.1 决策树，信息熵，id3, c4.5算法介绍</a><br/>
<a href="1.%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80.html">1.机器学习基础</a><br/>
<a href="2.5%20%20%E6%A0%87%E5%87%86%E6%96%B9%E7%A8%8B%E6%B3%95.html">2.5  标准方程法</a><br/>
<a href="4.2%20KNN%E5%AE%9E%E6%88%98.html">4.2 KNN实战</a><br/>
<a href="6.5%20ADABOOST%20%E8%87%AA%E9%80%82%E5%BA%94%E5%A2%9E%E5%BC%BA%E7%AE%97%E6%B3%95.html">6.5 ADABOOST 自适应增强算法</a><br/>
<a href="3.1%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%20%EF%BC%88%E5%A4%84%E7%90%86%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%EF%BC%89.html">3.1 逻辑回归 （处理分类问题）</a><br/>
<a href="6.2%20%E5%86%B3%E7%AD%96%E6%A0%91%E5%AE%9E%E6%88%98%E7%BB%83%E4%B9%A0.html">6.2 决策树实战练习</a><br/>
<a href="2.2%20%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0_1.html">2.2 代价函数</a><br/>
<a href="2.6%20%E7%89%B9%E5%BE%81%E7%BC%A9%E6%94%BE%EF%BC%8C%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E6%B3%95.html">2.6 特征缩放，交叉验证法</a><br/>
<a href="2.11%20%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92python%E8%AF%AD%E6%B3%95%E6%80%BB%E7%BB%93.html">2.11 线性回归python语法总结</a><br/>
<a href="7%20%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%20%E4%B8%80%E7%A7%8D%E6%80%9D%E6%83%B3.html">7 集成学习 一种思想</a><br/>
</body></html>